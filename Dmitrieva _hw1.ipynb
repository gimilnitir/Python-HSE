{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0cf65d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymystem3 in c:\\users\\balshan\\appdata\\roaming\\python\\python39\\site-packages (0.2.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from pymystem3) (2.28.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->pymystem3) (2022.9.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymystem3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83994cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pymorphy2 in c:\\users\\balshan\\appdata\\roaming\\python\\python39\\site-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\users\\balshan\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\users\\balshan\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\users\\balshan\\appdata\\roaming\\python\\python39\\site-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "11d60e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a59288a",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b58636a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('andreev.txt', encoding = \"utf8\") as f:\n",
    "    text = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dadc3bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53612253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8416a788",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = re.sub(r'\\n', \" \", text)\n",
    "text = re.sub(r'\\s{2,}', \" \", text)\n",
    "text = re.sub(r'\\ufeff', \" \", text) #getting rid of the formatting symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3ef3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas = m.lemmatize(text) #lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30ce7443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'леонид',\n",
       " ' ',\n",
       " 'андреев',\n",
       " ' ',\n",
       " 'рассказ',\n",
       " ' ',\n",
       " 'о',\n",
       " ' ',\n",
       " 'семь',\n",
       " ' ',\n",
       " 'повешенный',\n",
       " ' ',\n",
       " 'посвящаться',\n",
       " ' ',\n",
       " 'л',\n",
       " '. ',\n",
       " 'и',\n",
       " '. ',\n",
       " 'толстой']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aefe261e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmas.txt', 'w', encoding = \"utf8\") as f:\n",
    "    for word in lemmas:\n",
    "        f.write(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "03a920e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Balshan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Balshan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f23e2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = nltk.word_tokenize(text) #tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ba0ef0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Леонид',\n",
       " 'Андреев',\n",
       " 'Рассказ',\n",
       " 'о',\n",
       " 'семи',\n",
       " 'повешенных',\n",
       " 'Посвящается',\n",
       " 'Л.',\n",
       " 'И.',\n",
       " 'Толстому',\n",
       " '1',\n",
       " '.',\n",
       " 'В',\n",
       " 'ЧАС',\n",
       " 'ДНЯ',\n",
       " ',',\n",
       " 'ВАШЕ',\n",
       " 'ПРЕВОСХОДИТЕЛЬСТВО',\n",
       " 'Так',\n",
       " 'как']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens [:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a0e5635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "morph = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c7a9ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = []\n",
    "for word in tokens:\n",
    "    dict = {}\n",
    "    lemma = morph.parse(word)[0][2]\n",
    "    word = morph.parse(word)[0][0]\n",
    "    pos = str(morph.parse(word)[0][1]).split(\",\")[0]\n",
    "    dict[\"lemma\"] = lemma\n",
    "    dict[\"word\"] = word\n",
    "    dict[\"pos\"] = pos\n",
    "    analysis.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e2490a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lemma': 'леонид', 'word': 'леонид', 'pos': 'NOUN'},\n",
       " {'lemma': 'андреев', 'word': 'андреев', 'pos': 'NOUN'},\n",
       " {'lemma': 'рассказ', 'word': 'рассказ', 'pos': 'NOUN'},\n",
       " {'lemma': 'о', 'word': 'о', 'pos': 'PREP'},\n",
       " {'lemma': 'семь', 'word': 'семи', 'pos': 'NUMR gent'},\n",
       " {'lemma': 'повесить', 'word': 'повешенных', 'pos': 'PRTF'},\n",
       " {'lemma': 'посвящаться', 'word': 'посвящается', 'pos': 'VERB'},\n",
       " {'lemma': 'л.', 'word': 'л.', 'pos': 'UNKN'},\n",
       " {'lemma': 'и.', 'word': 'и.', 'pos': 'UNKN'},\n",
       " {'lemma': 'толстой', 'word': 'толстому', 'pos': 'NOUN'},\n",
       " {'lemma': '1', 'word': '1', 'pos': 'NUMB'},\n",
       " {'lemma': '.', 'word': '.', 'pos': 'PNCT'},\n",
       " {'lemma': 'в', 'word': 'в', 'pos': 'PREP'},\n",
       " {'lemma': 'час', 'word': 'час', 'pos': 'NOUN'},\n",
       " {'lemma': 'день', 'word': 'дня', 'pos': 'NOUN'},\n",
       " {'lemma': ',', 'word': ',', 'pos': 'PNCT'},\n",
       " {'lemma': 'ваш', 'word': 'ваше', 'pos': 'ADJF'},\n",
       " {'lemma': 'превосходительство', 'word': 'превосходительство', 'pos': 'NOUN'},\n",
       " {'lemma': 'так', 'word': 'так', 'pos': 'CONJ'},\n",
       " {'lemma': 'как', 'word': 'как', 'pos': 'CONJ'}]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis[:20] #morphological analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0df0698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('analized.json', 'w') as f:\n",
    "    json.dump(analysis, f) #saving as json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9486ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "914e06fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "adverb = []\n",
    "for x in range(len(analysis)):\n",
    "    if \"ADVB\" in analysis[x].values():\n",
    "        adverb.append(analysis[x]['lemma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1a3d36de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ещё', 88),\n",
       " ('вдруг', 72),\n",
       " ('только', 70),\n",
       " ('уже', 58),\n",
       " ('ничего', 52),\n",
       " ('теперь', 40),\n",
       " ('очень', 39),\n",
       " ('потом', 39),\n",
       " ('быстро', 35),\n",
       " ('несколько', 34),\n",
       " ('точно', 34),\n",
       " ('что-то', 32),\n",
       " ('совсем', 31),\n",
       " ('тут', 26),\n",
       " ('хорошо', 25),\n",
       " ('снова', 24),\n",
       " ('тихо', 24),\n",
       " ('где', 22),\n",
       " ('почти', 22),\n",
       " ('громко', 19)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adverb_count = Counter(adverb)\n",
    "sorted(adverb_count.items(), key=lambda x: x[1], reverse = True)[:20] #counting top 20 adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25ceca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('быть', 243),\n",
       " ('сказать', 90),\n",
       " ('мочь', 59),\n",
       " ('стать', 55),\n",
       " ('говорить', 41),\n",
       " ('хотеть', 39),\n",
       " ('знать', 35),\n",
       " ('думать', 35),\n",
       " ('казаться', 32),\n",
       " ('ответить', 29),\n",
       " ('начать', 21),\n",
       " ('становиться', 20),\n",
       " ('спросить', 20),\n",
       " ('смотреть', 20),\n",
       " ('идти', 18),\n",
       " ('молчать', 17),\n",
       " ('подумать', 17),\n",
       " ('умереть', 16),\n",
       " ('стоять', 16),\n",
       " ('бояться', 16)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verb = []\n",
    "for x in range(len(analysis)):\n",
    "    if \"VERB\" in analysis[x].values():\n",
    "        verb.append(analysis[x]['lemma'])\n",
    "\n",
    "verb_count = Counter(verb)\n",
    "sorted(verb_count.items(), key=lambda x: x[1], reverse = True)[:20] #counting top 20 verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3beedeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6fb31aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_new = text.translate(str.maketrans(' ', ' ', string.punctuation)) #getting rid of punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f3ad10ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_new = m.lemmatize(text_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "27455994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'леонид',\n",
       " ' ',\n",
       " 'андреев',\n",
       " ' ',\n",
       " 'рассказ',\n",
       " ' ',\n",
       " 'о',\n",
       " ' ',\n",
       " 'семь',\n",
       " ' ',\n",
       " 'повешенный',\n",
       " ' ',\n",
       " 'посвящаться',\n",
       " ' ',\n",
       " 'л',\n",
       " ' ',\n",
       " 'и',\n",
       " ' ',\n",
       " 'толстой']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmas_new[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3ba673b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmas_new = ''.join(lemmas_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9190cce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_new = nltk.word_tokenize(lemmas_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b2cf7f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('и', 'не'), 40),\n",
       " (('как', 'будто'), 30),\n",
       " (('то', 'что'), 30),\n",
       " (('не', 'быть'), 30),\n",
       " (('ничто', 'не'), 26),\n",
       " (('я', 'не'), 26),\n",
       " (('не', 'знать'), 24),\n",
       " (('он', 'и'), 24),\n",
       " (('не', 'мочь'), 23),\n",
       " (('и', 'с'), 21),\n",
       " (('и', 'так'), 20),\n",
       " (('он', 'быть'), 19),\n",
       " (('он', 'не'), 19),\n",
       " (('и', 'в'), 18),\n",
       " (('рука', 'и'), 18),\n",
       " (('так', 'же'), 18),\n",
       " (('и', 'все'), 18),\n",
       " (('и', 'это'), 17),\n",
       " (('и', 'вдруг'), 17),\n",
       " (('сергей', 'головин'), 17),\n",
       " (('и', 'как'), 17),\n",
       " (('тот', 'же'), 16),\n",
       " (('у', 'он'), 16),\n",
       " (('а', 'я'), 16),\n",
       " (('вернер', 'и'), 16)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bg = list(bigrams(tokens_new))\n",
    "bcount = Counter(bg)\n",
    "sorted(bcount.items(), key=lambda x: x[1], reverse = True)[:25] #finding top 25 bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "22973d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import collocations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b6dc2593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.collocations import *\n",
    "trigram_measures = nltk.collocations.TrigramAssocMeasures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "19149505",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('мой', 'любовь', 'широкий'),\n",
       " ('день', 'ваш', 'превосходительство'),\n",
       " ('казнь', 'через', 'повешение'),\n",
       " ('смертный', 'казнь', 'через'),\n",
       " ('весь', 'скорбеть', 'радость'),\n",
       " ('час', 'день', 'ваш'),\n",
       " ('к', 'смертный', 'казнь'),\n",
       " ('любовь', 'широкий', 'как'),\n",
       " ('широкий', 'как', 'море'),\n",
       " ('скорбеть', 'радость', 'и'),\n",
       " ('не', 'надо', 'вешать'),\n",
       " ('в', 'час', 'день'),\n",
       " ('один', 'за', 'другой'),\n",
       " ('ничто', 'не', 'знать'),\n",
       " ('я', 'не', 'надо'),\n",
       " ('я', 'не', 'хотеть'),\n",
       " ('сергей', 'головин', 'и'),\n",
       " ('не', 'хотеть', 'сказать'),\n",
       " ('что', 'же', 'это'),\n",
       " ('и', 'трудно', 'быть'),\n",
       " ('как', 'же', 'я'),\n",
       " ('жизнь', 'и', 'смерть'),\n",
       " ('у', 'он', 'быть'),\n",
       " ('и', 'как', 'будто'),\n",
       " ('в', 'то', 'что')]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finder = TrigramCollocationFinder.from_words(tokens_new)\n",
    "finder.apply_freq_filter(4)   #I picked up manually the appropriate frequency rating, if it is more than 4, the number of most frequent trigrams is less than 25 \n",
    "finder.nbest(trigram_measures.pmi, 25)\n",
    "\n",
    "#There is a tendency that the top-25 bigrams mostly include functional words, like conjunctions and prepositions.\n",
    "#The situation is different for the top-25 trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0da1da8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26823\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens)) #counting total number of vords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b6f618df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13048503150281474\n"
     ]
    }
   ],
   "source": [
    "v=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"VERB\" in analysis[x].values():\n",
    "        v = v+1\n",
    "for x in range(len(analysis)):\n",
    "    if \"INFN\" in analysis[x].values():\n",
    "        v = v+1        \n",
    "print (v/(len(tokens))) #percentage of verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aff13dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17212839727099877\n"
     ]
    }
   ],
   "source": [
    "n=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"NOUN\" in analysis[x].values():\n",
    "        n = n+1\n",
    "print (n/(len(tokens))) #percentage of nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "32d1b529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08418148603810163\n"
     ]
    }
   ],
   "source": [
    "adj=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"ADJS\" in analysis[x].values():\n",
    "        adj = adj+1\n",
    "for x in range(len(analysis)):\n",
    "    if \"ADJF\" in analysis[x].values():\n",
    "        adj = adj+1\n",
    "print (adj/(len(tokens))) #percentage of adjestives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b0d2794f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07318346195429296\n"
     ]
    }
   ],
   "source": [
    "advb=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"ADVB\" in analysis[x].values():\n",
    "        advb = advb+1\n",
    "print (advb/(len(tokens))) #percentage of adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ea3ba834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06330388099765127\n"
     ]
    }
   ],
   "source": [
    "prep=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"PREP\" in analysis[x].values():\n",
    "        prep = prep+1\n",
    "print (prep/(len(tokens))) #percentage of prepositions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0d3dac20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1062148156432912\n"
     ]
    }
   ],
   "source": [
    "cn=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"CONJ\" in analysis[x].values():\n",
    "        cn = cn+1\n",
    "print (cn/(len(tokens))) #percentage of conjunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7703eb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00041009581329456063\n"
     ]
    }
   ],
   "source": [
    "nm=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"NUMR\" in analysis[x].values():\n",
    "        nm = nm+1\n",
    "print (nm/(len(tokens))) #percentage of numerals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2b6a1db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043582000521940126\n"
     ]
    }
   ],
   "source": [
    "prcl=0\n",
    "for x in range(len(analysis)):\n",
    "    if \"PRCL\" in analysis[x].values():\n",
    "        prcl = prcl+1\n",
    "print (prcl/(len(tokens))) #percentage of particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a333b024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
